{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "simple_rnn.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORk7IEfRnNdO"
      },
      "source": [
        "# Simple RNN \n",
        "\n",
        "In this notebook we consider a simple example of an RNN and used a quite artifical data generating process (if you have a better idea / story please contact me). \n",
        "\n",
        "The example has been motivated by:\n",
        "http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html. \n",
        "\n",
        "Other Resources for RNNs:\n",
        "\n",
        "* http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n",
        "* http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html\n",
        "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "* http://www.deeplearningbook.org/contents/rnn.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrsZGNr-nNdS",
        "outputId": "dd3be0b6-f082-4cff-9457-319e48fd645d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from six.moves.cPickle import loads\n",
        "import numpy as np\n",
        "import sys\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "keras = tensorflow.keras\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "tf.__version__, sys.version_info"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.3.0',\n",
              " sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkWMDn1gnNdT"
      },
      "source": [
        "# Global config variables (see below)\n",
        "num_steps = 40     # number of truncated backprop steps\n",
        "batch_size = 200  # number of minibatches b\n",
        "num_classes_in = 3   # number of classes in the input\n",
        "num_classes_out = 2   # number of classes in the output\n",
        "state_size = 4    # number of classes in the state\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Helper functions\n",
        "def one_hot(Y, max):\n",
        "    d = np.zeros((len(Y),max), dtype='int32')\n",
        "    for row,col in enumerate(Y):\n",
        "        d[row, col] = 1\n",
        "    return d    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_abito8nNdU"
      },
      "source": [
        "### Definition of the task\n",
        "\n",
        "We consider a network which predicts at each point in time a variable $\\hat{y}_t$ based on earlier values of $\\hat{y}_{t'}$ covariates $x_t$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHII6zIHnNdU"
      },
      "source": [
        "### Example data  (I screama, you screama, we all screama for I screama)\n",
        "\n",
        "We need some data to play around with RNNs. They are capable of doing quite complicated things such as language models and so on. For this example, we want to generate the data ourself. We have to come up with a process which creates $x_t$ which itself can be influcenced by events $x_{t'}$ which happend before $t$. Further, we have to come up with $y_t$ which depends on $x_t'$ for timepoints $t' \\le t$. \n",
        "\n",
        "To keep it simple, we analyse the following quite artifical process in which the weather $x_{t'}$ for $t' \\le t$ influences our stock on icecream $y_t$. We then see if the RNN is capable of reconstructing that process.\n",
        "\n",
        "#### Definition of the simple process\n",
        "The weather $x_t$ at a certain point in time $t$ has three states (sunny, rainy, cloudy), which we model as $x_t = (1,0,0)$, $x_t = (0,1,0)$, and $x_t = (0,0,1)$ repectively. We assume that the weather is completly random (of course we could model more complex scenarios). \n",
        "\n",
        "We have an icecream store capable of holding 2 units of icecream and we start with a full store. When it is sunny we sell one unit of icecream. We have the strange policy that we order  on unit of icecream when it's cloudy. It takes 3 days to deliever the ice cream, we accept the ice cream if we do not have a full stock.\n",
        "\n",
        "This enables us to model $y_t$ the state of the store $(1,0)$ for out of stock and $(0,1)$ for in stock. We create the one-hot-encoded data in the graph later. For now we use integers but keep in mind that the data is categorical. \n",
        "\n",
        "** The important part is that, we have values $y_t$ which can be prediced from earlier** $x_t$s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv49fA2bnNdU"
      },
      "source": [
        "def gen_data(size=1000000):\n",
        "    Xs = np.array(np.random.choice(3, size=(size,))) #Random Weather\n",
        "    Y = []\n",
        "    ice = 2 #Our stock of icecream at start\n",
        "    for t,x in enumerate(Xs):\n",
        "        # (t-3) >= 0 the first ice cream could be delivered on day 3\n",
        "        # Xs[t - 3] claudy three days before today => we ordered ice cream\n",
        "        # ice < 2 not full\n",
        "        if (t - 3) >= 0 and Xs[t - 3] == 1 and ice < 2: \n",
        "            ice += 1\n",
        "        if x == 0: # It is sunny we therefore sell ice, if we have\n",
        "            if ice > 0: # We have ice cream\n",
        "                ice -= 1\n",
        "        if ice > 0: #We are not out of stock\n",
        "            Y.append(1)\n",
        "        else:\n",
        "            Y.append(0)\n",
        "    return Xs, np.array(Y)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwDJUmFFnNdV",
        "outputId": "77ae5392-e406-4456-c6c7-e996945c26eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train, Y_train = gen_data(50000) #Global variables holding the input and output\n",
        "(X_train[0:50], Y_train[0:50])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0,\n",
              "        0, 2, 1, 0, 1, 1]),\n",
              " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL6n3fqynNdV"
      },
      "source": [
        "# Forward pass in numpy\n",
        "To better illustrate the used method, we first do a forward-pass of the RNN using numpy. We load the weights which we calculated previously with the cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LEkG78cJaiR",
        "outputId": "9a114c4d-d6d4-4558-b538-e3c9cd311440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/ioskn/mldl_htwg/master/rnns/rnn_weights_tf1.npy' "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-15 11:27:15--  https://raw.githubusercontent.com/ioskn/mldl_htwg/master/rnns/rnn_weights_tf1.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 774 [application/octet-stream]\n",
            "Saving to: ‘rnn_weights_tf1.npy.3’\n",
            "\n",
            "\rrnn_weights_tf1.npy   0%[                    ]       0  --.-KB/s               \rrnn_weights_tf1.npy 100%[===================>]     774  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-15 11:27:15 (41.6 MB/s) - ‘rnn_weights_tf1.npy.3’ saved [774/774]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kjxPh-XnNdV"
      },
      "source": [
        "np.load('rnn_weights_tf1.npy', allow_pickle=True)\n",
        "W_, b_, V_, bv_ = np.load('rnn_weights_tf1.npy', allow_pickle=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0scP6j3nNdV"
      },
      "source": [
        "### Architecture of the network \n",
        "We now define the network, we do not consider the output nodes yet.\n",
        "A single RNN cell is shown in the figure below in the middle:\n",
        "\n",
        "![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n",
        "Image taken from: [Colah's RNN Blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "The joining of the two lines coming from the previous state $h_{t-1}$ and the current x-values $x_t$ is a concantination to a vector  $[h_{t-1}, x_{t}]$ of size `state_size + num_classes_in`. Alternatively, instead of concatinating, one could also use two matrices $W_x$ and $W_h$ and keep the states seperate. This is mathematically completely identical. The new state $h_t$ is then calculated as:\n",
        "\n",
        "$$\n",
        "    h_{t} = \\tanh([h_{t-1}, x_{t}] \\cdot W + b) = \\tanh(h_{t-1} \\cdot W_h + x_{t} \\cdot U + b)\n",
        "$$\n",
        "\n",
        "The dynamic of the hidden state $h_{t}$ is determined by $W$ (and $b$):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfm4sKQVnNdW",
        "outputId": "3d90fa9d-6f92-47dc-89e4-3aaaead32985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Internal states\n",
        "print(W_.shape)\n",
        "print(b_.shape)\n",
        "W_, b_"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 4)\n",
            "(4,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.19089293,  1.2079829 ,  0.00908419, -0.9110236 ],\n",
              "        [-1.0788563 , -0.34288317,  0.7271212 ,  1.4178839 ],\n",
              "        [-0.20597383, -0.19254826,  0.7025221 , -0.54543966],\n",
              "        [ 1.0341463 ,  0.67596245, -0.93610775,  0.37894768],\n",
              "        [-0.16711316,  1.0264009 , -0.89726377, -0.42267284],\n",
              "        [ 0.20204762, -1.2146151 ,  0.02345279,  0.41776735],\n",
              "        [-1.4482121 ,  0.28976035, -1.8760067 , -1.1563133 ]],\n",
              "       dtype=float32),\n",
              " array([ 0.1347418 ,  0.28151226,  0.17300364, -0.321079  ], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncXYqITTnNdW",
        "outputId": "748e08e1-bbb6-4e84-9671-598f12393bab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Connecting to the outpur\n",
        "print(V_.shape)\n",
        "print(bv_.shape)\n",
        "V_, bv_"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 2)\n",
            "(2,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.18110763,  0.14144787],\n",
              "        [ 2.2433083 , -3.244251  ],\n",
              "        [-0.05769794,  0.35383844],\n",
              "        [ 0.0802527 , -0.5142712 ]], dtype=float32),\n",
              " array([-0.35922614,  0.35923496], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srUfVMPHnNdW",
        "outputId": "ed47a8a3-b1f1-4490-a0f7-7f33b6613ff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The first state\n",
        "h0 = np.zeros(state_size) #We start with 0 initial state\n",
        "x1 = one_hot(X_train, num_classes_in)[0] #Make a vector\n",
        "h1 = np.tanh(np.matmul(np.concatenate([x1, h0]), W_) + b_)\n",
        "print(h0, \"--->\", h1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0.] ---> [-0.0711118   0.08873004  0.70417075 -0.69960102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9lBoX_xnNdW"
      },
      "source": [
        "We could repeat those transitions of the hidden states to get a sequence of hidden states:\n",
        "\n",
        "$h_0 \\rightarrow h_1 \\rightarrow h_2 \\rightarrow h_3 \\rightarrow h_4 \\ldots $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7OQe-qdnNdX"
      },
      "source": [
        "def rnn_forward(state, X_train):\n",
        "    hs = []\n",
        "    for t in range(len(X_train)):\n",
        "        # Note that TF concatenates [Input, State]\n",
        "        state = np.tanh(np.matmul(np.concatenate([X_train[t,:],state]), W_) + b_)\n",
        "        hs.append(state)\n",
        "    return hs"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk51T20hnNdX",
        "outputId": "50eb235f-1f21-45f8-c7ad-b491f75e41ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnn_forward(h0, one_hot(X_train[0:5],num_classes_in))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.0711118 ,  0.08873004,  0.70417075, -0.69960102]),\n",
              " array([ 0.76614542,  0.4418166 ,  0.90478852, -0.19104017]),\n",
              " array([ 0.80289923, -0.09371934,  0.14058029, -0.16258438]),\n",
              " array([ 0.77733682,  0.30737024,  0.47485703, -0.26912559]),\n",
              " array([ 0.82809942,  0.93229872, -0.29620752, -0.50640012])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHG7eaa4nNdX"
      },
      "source": [
        "We add some output. For each time step the output is produced by multiplying the hidden state with:\n",
        "\n",
        "$o_t = h_t \\cdot V + b_{\\tt{v}}$\n",
        "\n",
        "This is a logit, the final the probability of output class is the softmax of the logit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic9nxmMtnNdX",
        "outputId": "bb7593ca-a145-49e7-e2d4-3f5947da317c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#<---- your code here (calculate the output state o1 for timestep 1 from h1, V_ and the bias bv_) ---->\n",
        "o1 = np.matmul(h1, V_) + bv_\n",
        "#<---- your code here (calculate probability from the state o1) using softmax ---->\n",
        "prob_1 = np.exp(o1)/np.sum(np.exp(o1))\n",
        "#<---- end your code here  ---->\n",
        "o1, prob_1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.24407249,  0.67026118]), array([0.28611385, 0.71388615]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMy2z_NMnNdY"
      },
      "source": [
        "h = rnn_forward(h0, one_hot(X_train,3))\n",
        "pt = []\n",
        "for t in range(len(h)):\n",
        "    ot = np.matmul(h[t], V_) + bv_\n",
        "    pt.append(np.exp(ot)/np.sum(np.exp(ot)))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyrWKuKonNdY",
        "outputId": "f43ea891-85e0-465c-c077-d73899810103",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pt[0:10], np.argmax(pt[0:30],axis=1), Y_train[0:30]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([0.28611385, 0.71388615]),\n",
              "  array([0.72571267, 0.27428733]),\n",
              "  array([0.16161706, 0.83838294]),\n",
              "  array([0.58954736, 0.41045264]),\n",
              "  array([0.98113328, 0.01886672]),\n",
              "  array([0.98589376, 0.01410624]),\n",
              "  array([0.9805026, 0.0194974]),\n",
              "  array([0.97813046, 0.02186954]),\n",
              "  array([0.98805885, 0.01194115]),\n",
              "  array([0.96179709, 0.03820291])],\n",
              " array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0]),\n",
              " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi-PvY0jnNdY",
        "outputId": "447ec963-cd2e-43fb-afdc-96bcaa257a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.average(np.argmax(pt, axis=1) == Y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeXUWg9RnNdY"
      },
      "source": [
        "tot_loss = 0\n",
        "for i in range(len(Y_train)):\n",
        "    tot_loss += -np.log(pt[i][Y_train[i]])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPK9SD2mnNda",
        "outputId": "599a17ba-6386-4b1e-f782-f31e1674aa01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tot_loss / len(Y_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06928991983381634"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LhUX-xInNda"
      },
      "source": [
        "# Training of the network\n",
        "## Preparation of the Minibatch\n",
        "\n",
        "In this example, we have in principle a large stream of data $x$ and $y$. For efficiency reason we split the stream in minibatches of a certain length. For this task we could also imagin to have several realizations of that icecream process, so that it would also be natural to split the process into mini batches. \n",
        "\n",
        "For simplicity, we create the minibatch by randomly cutting out `batch_size` entries of fixed length `num_steps`. Other, more advanced ways of doing so are possible. See e.g. https://danijar.com/variable-sequence-lengths-in-tensorflow/. For the time being, we thus consider the input tensor $X_{btc}$ for the minibatch to be of the following form:\n",
        "\n",
        "* $b$ having `batch_size` entries\n",
        "* $t$ loops over the unrolled timestamps (`num_steps`)\n",
        "* $c$ has the dimension of the one-hot-coded input classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Dmftz1nNda"
      },
      "source": [
        "def data_matrix(Xs, Ys, size = 32, num_steps = 50):\n",
        "    data_x = np.zeros([size, num_steps, 3], dtype=np.int32)\n",
        "    data_y = np.zeros([size, num_steps, 2], dtype=np.int32)\n",
        "    for i in range(1,size):\n",
        "        s = int(np.random.uniform(0, len(Xs) - num_steps))\n",
        "        data_x[i] = one_hot(Xs[s : s + num_steps],3)\n",
        "        data_y[i] = one_hot(Ys[s : s + num_steps],2)\n",
        "    return data_x, data_y"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDf8RVD6nNda",
        "outputId": "60e0bb3d-6378-47c2-a90b-a0fae74d40b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X, Y = data_matrix(X_train, Y_train, size=10000, num_steps=num_steps)\n",
        "X.shape, Y.shape\n",
        "#print (X[0:2,0:5])\n",
        "#print (Y[0:2,0:5])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 40, 3), (10000, 40, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9BtVQrDnNda"
      },
      "source": [
        "## Building the model with keras\n",
        "\n",
        "**Keras assumes (batch, time, input_dimension)** as input tensor. The batch dimension needs not to be specified (side note that specifying it to `None` would not work).\n",
        "\n",
        "\n",
        "In our model we calculate the loss using all hidden timepoints. This is many-to-many situation is different for example to a sentiment classifier, where we we have a many-to-one situation. \n",
        "\n",
        "Not just the latest one (in time). Hence we set `return_sequences=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ryBjmmDnNdb",
        "outputId": "f8c0794e-b590-43ae-b68c-daede2c9d197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "rnn = keras.layers.SimpleRNN(state_size, input_shape=(num_steps, 3), return_sequences=True, name='RNN')\n",
        "model.add(rnn) \n",
        "#model.input_shape --> (None, 40, 3)\n",
        "#model.output_shape --> (None, 40, 4) \n",
        "\n",
        "# <-- Your code here \n",
        "# Add an output layer connecting with the hidden state of the RNN\n",
        "model.add(keras.layers.Dense(2))\n",
        "# <-- End code here \n",
        "\n",
        "#model.output_shape --> (None, 40, 2) \n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "RNN (SimpleRNN)              (None, 40, 4)             32        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 40, 2)             10        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZB577WNnNdb"
      },
      "source": [
        "For the RNN we have: \n",
        "\n",
        "Internal: (4+3)*4 + 4 = 32\n",
        "\n",
        "Output: 4*2+2 = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB368pnWnNdb",
        "outputId": "33d0e8e9-5b45-4d29-ae1f-b91ce693e79a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "source": [
        "history = model.fit(X, Y, epochs=100, verbose=2, validation_split=0.05)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "297/297 - 2s - loss: 2.7725 - accuracy: 0.5077 - val_loss: 1.4049 - val_accuracy: 0.5159\n",
            "Epoch 2/100\n",
            "297/297 - 2s - loss: 0.8001 - accuracy: 0.5775 - val_loss: 0.6891 - val_accuracy: 0.6773\n",
            "Epoch 3/100\n",
            "297/297 - 2s - loss: 0.6075 - accuracy: 0.7032 - val_loss: 0.5575 - val_accuracy: 0.7572\n",
            "Epoch 4/100\n",
            "297/297 - 2s - loss: 0.4775 - accuracy: 0.7888 - val_loss: 0.4317 - val_accuracy: 0.8158\n",
            "Epoch 5/100\n",
            "297/297 - 2s - loss: 0.4146 - accuracy: 0.8177 - val_loss: 0.4122 - val_accuracy: 0.8213\n",
            "Epoch 6/100\n",
            "297/297 - 2s - loss: 0.3941 - accuracy: 0.8257 - val_loss: 0.3865 - val_accuracy: 0.8307\n",
            "Epoch 7/100\n",
            "297/297 - 2s - loss: 0.3627 - accuracy: 0.8401 - val_loss: 0.3433 - val_accuracy: 0.8528\n",
            "Epoch 8/100\n",
            "297/297 - 2s - loss: 0.3143 - accuracy: 0.8656 - val_loss: 0.2920 - val_accuracy: 0.8813\n",
            "Epoch 9/100\n",
            "297/297 - 2s - loss: 0.2698 - accuracy: 0.8965 - val_loss: 0.2584 - val_accuracy: 0.9052\n",
            "Epoch 10/100\n",
            "297/297 - 2s - loss: 0.2534 - accuracy: 0.9134 - val_loss: 0.2510 - val_accuracy: 0.9151\n",
            "Epoch 11/100\n",
            "297/297 - 2s - loss: 0.2526 - accuracy: 0.9183 - val_loss: 0.2654 - val_accuracy: 0.9204\n",
            "Epoch 12/100\n",
            "297/297 - 2s - loss: 0.2555 - accuracy: 0.9231 - val_loss: 0.2616 - val_accuracy: 0.9233\n",
            "Epoch 13/100\n",
            "297/297 - 2s - loss: 0.2497 - accuracy: 0.9279 - val_loss: 0.2558 - val_accuracy: 0.9263\n",
            "Epoch 14/100\n",
            "297/297 - 2s - loss: 0.2397 - accuracy: 0.9321 - val_loss: 0.2439 - val_accuracy: 0.9293\n",
            "Epoch 15/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-974d0d7ae04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2exjxsynNdb",
        "outputId": "e8bd83bb-d172-4cda-a45b-db102c45b9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "# plot the development of the accuracy and loss during training\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,(1))\n",
        "plt.plot(history.history['accuracy'],linestyle='-.')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='lower right')\n",
        "plt.subplot(1,2,(2))\n",
        "plt.plot(history.history['loss'],linestyle='-.')\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper right')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b129446be11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRD9uGUmnNdc"
      },
      "source": [
        "# We use the training, since we did use only a random subset of the data\n",
        "X, Y = data_matrix(X_train, Y_train, size=1000, num_steps=num_steps)\n",
        "model.evaluate(X,Y, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjCCeYc3nNdc"
      },
      "source": [
        "rnn.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKm3zOWpnNdc"
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW7IWDQanNdc"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.GRU(state_size, return_sequences=True, input_shape=(num_steps, 3)))\n",
        "rnn = keras.layers.LSTM(state_size, return_sequences=True) #Need to be true\n",
        "model.add(rnn) \n",
        "\n",
        "#model.input_shape --> (None, 40, 3)\n",
        "#model.output_shape --> (None, 40, 4) \n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(2))\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z9GmZiFnNdc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq-4qKDBnNdc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvx8Wp43nNdc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBtybB_BnNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLScscUTnNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr5fKqkDnNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEQkaAF6nNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7puYxiAnNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q65Hgs9UnNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF_YKRnanNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBIOg_gZnNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IbwyqLBnNdd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r46OZQN0nNde"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdtDLXNmnNde"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}